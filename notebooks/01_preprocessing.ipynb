{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this #earthquake M...\n",
       "1               Forest fire near La Ronge Sask. Canada\n",
       "2    All residents asked to 'shelter in place' are ...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    Just got sent this photo from Ruby #Alaska as ...\n",
       "5    #RockyFire Update => California Hwy. 20 closed...\n",
       "6    #flood #disaster Heavy rain causes flash flood...\n",
       "7    I'm on top of the hill and I can see a fire in...\n",
       "8    There's an emergency evacuation happening now ...\n",
       "9    I'm afraid that the tornado is coming to our a...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = re.compile(' https?://\\S+|www\\.\\S+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M1.94 [01:04 UTC]?5km S of Volcano Hawaii.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url.sub('', 'M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M1.94 [01:04 UTC]?5km S of Volcano Hawaii.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url.sub('', 'M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = unidecode.unidecode(text) # Quitamos los acentos\n",
    "    \n",
    "    text = re.sub('\\[.*?\\]', '', text) # Borramos todos los corchetes ejemplo: [hola mama]\n",
    "    \n",
    "    text_without_url = re.sub('https?://\\S+|www\\.\\S+', '', text) # Quitamos los enlaces\n",
    "    \n",
    "    text_without_tag = re.sub('<.*?>+', '', text_without_url) # Quitamos expresiones de tipo <xxx>\n",
    "    \n",
    "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text_without_tag) # Titamos caracteres como ['!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~']\n",
    "    \n",
    "    text = re.sub('\\n', '', text) # Quitamos los saltos de lineas\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # Quitamos palabras con numeros ocodigos    \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.text = train.text.apply(preprocessing)\n",
    "test.text = test.text.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    our deeds are the reason of this earthquake ma...\n",
       "1                forest fire near la ronge sask canada\n",
       "2    all residents asked to shelter in place are be...\n",
       "3     people receive wildfires evacuation orders in...\n",
       "4    just got sent this photo from ruby alaska as s...\n",
       "5    rockyfire update  california hwy  closed in bo...\n",
       "6    flood disaster heavy rain causes flash floodin...\n",
       "7    im on top of the hill and i can see a fire in ...\n",
       "8    theres an emergency evacuation happening now i...\n",
       "9     im afraid that the tornado is coming to our area\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.text = train.text.apply(tokenizer.tokenize)\n",
    "test.text = test.text.apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>623</td>\n",
       "      <td>arsonist</td>\n",
       "      <td>Adelaide, South Australia</td>\n",
       "      <td>[arsonists, being, blamed, for, a, blaze, at, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>8177</td>\n",
       "      <td>rescuers</td>\n",
       "      <td>USA - Canada - Europe - Asia</td>\n",
       "      <td>[video, were, picking, up, bodies, from, water...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>5298</td>\n",
       "      <td>fear</td>\n",
       "      <td>Athens - Nicosia</td>\n",
       "      <td>[couples, having, less, sex, for, fear, itll, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>9374</td>\n",
       "      <td>survived</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[by, the, grace, of, god, i, survived, the, sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>2440</td>\n",
       "      <td>collide</td>\n",
       "      <td>Pennsylvania, USA</td>\n",
       "      <td>[worlds, collide, when, an, american, family, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   keyword                      location  \\\n",
       "430    623  arsonist     Adelaide, South Australia   \n",
       "5730  8177  rescuers  USA - Canada - Europe - Asia   \n",
       "3727  5298      fear              Athens - Nicosia   \n",
       "6551  9374  survived                           NaN   \n",
       "1690  2440   collide             Pennsylvania, USA   \n",
       "\n",
       "                                                   text  target  \n",
       "430   [arsonists, being, blamed, for, a, blaze, at, ...       0  \n",
       "5730  [video, were, picking, up, bodies, from, water...       1  \n",
       "3727  [couples, having, less, sex, for, fear, itll, ...       0  \n",
       "6551  [by, the, grace, of, god, i, survived, the, sh...       0  \n",
       "1690  [worlds, collide, when, an, american, family, ...       0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.text = train.text.apply(lambda text: [w for w in text if w not in nltk.corpus.stopwords.words('english')])\n",
    "test.text = test.text.apply(lambda text: [w for w in text if w not in nltk.corpus.stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.text = train.text.apply(lambda text: ' '.join(text))\n",
    "test.text = test.text.apply(lambda text: ' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         deeds reason earthquake may allah forgive us\n",
       "1                forest fire near la ronge sask canada\n",
       "2    residents asked shelter place notified officer...\n",
       "3    people receive wildfires evacuation orders cal...\n",
       "4    got sent photo ruby alaska smoke wildfires pou...\n",
       "5    rockyfire update california hwy closed directi...\n",
       "6    flood disaster heavy rain causes flash floodin...\n",
       "7                           im top hill see fire woods\n",
       "8    theres emergency evacuation happening building...\n",
       "9                        im afraid tornado coming area\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text[:10]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4547dae46a4e2d47e5e7e81c258ee8f975cc6d9ac4fdf92fab0d557a46ed73a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nlpenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
